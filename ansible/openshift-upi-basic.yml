---
- name: OpenShift UPI Complete Deployment Automation
  hosts: localhost
  gather_facts: false
  vars_files:
    - ansible-vars.yml
  
  tasks:
    # ================================
    # 1. Prerequisites Validation
    # ================================
    
    - name: Verify required tools are installed
      command: "{{ item }} --version"
      register: tool_check
      failed_when: tool_check.rc != 0
      changed_when: false
      loop:
        - terraform
        - openshift-install
        - gcloud
      tags: [prerequisites]

    - name: Check if gcloud is authenticated
      command: gcloud auth list --filter=status:ACTIVE --format="value(account)"
      register: gcloud_auth
      failed_when: gcloud_auth.stdout == ""
      changed_when: false
      tags: [prerequisites]

    - name: Verify SSH key exists
      stat:
        path: "{{ ssh_key_path }}"
      register: ssh_key_stat
      failed_when: not ssh_key_stat.stat.exists
      tags: [prerequisites]

    - name: Verify install-config.yaml exists
      stat:
        path: "../config/install-config.yaml"
      register: install_config_stat
      failed_when: not install_config_stat.stat.exists
      tags: [prerequisites]

    - name: Verify terraform.tfvars exists
      stat:
        path: "../terraform/terraform.tfvars"
      register: terraform_vars_stat
      failed_when: not terraform_vars_stat.stat.exists
      tags: [prerequisites]

    # ================================
    # 2. OpenShift Ignition Generation
    # ================================
    
    - name: Clean previous cluster configuration
      file:
        path: "../clusterconfig"
        state: absent
      tags: [ignition]

    - name: Create clusterconfig directory
      file:
        path: "../clusterconfig"
        state: directory
        mode: '0755'
      tags: [ignition]

    - name: Copy install-config.yaml to clusterconfig
      copy:
        src: "../config/install-config.yaml"
        dest: "../clusterconfig/install-config.yaml"
        mode: '0644'
      tags: [ignition]

    - name: Generate OpenShift ignition configs
      command: openshift-install create ignition-configs --dir=../clusterconfig
      register: ignition_result
      tags: [ignition]

    - name: Verify ignition files were created
      stat:
        path: "../clusterconfig/{{ item }}"
      register: ignition_files
      failed_when: not ignition_files.stat.exists
      loop:
        - bootstrap.ign
        - master.ign
        - worker.ign
      tags: [ignition]

    - name: Display ignition generation status
      debug:
        msg: "âœ“ OpenShift ignition configs generated successfully"
      tags: [ignition]

    # ================================
    # 3. RHCOS Image Management
    # ================================
    
    - name: Check if RHCOS image exists in GCP
      shell: gcloud compute images describe {{ rhcos_image_name }} --format="value(name)" 2>/dev/null || echo "not_found"
      register: rhcos_image_check
      changed_when: false
      tags: [rhcos]

    - name: Display RHCOS image status
      debug:
        msg: "RHCOS image {{ rhcos_image_name }}: {{ 'EXISTS' if rhcos_image_check.stdout != 'not_found' else 'NOT FOUND - will download and upload' }}"
      tags: [rhcos]

    - name: Create artifacts directory
      file:
        path: "../artifacts"
        state: directory
        mode: '0755'
      when: rhcos_image_check.stdout == "not_found"
      tags: [rhcos]

    - name: Download RHCOS image
      get_url:
        url: "https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos/4.19/{{ rhcos_version }}/rhcos-{{ rhcos_version }}-x86_64-gcp.x86_64.tar.gz"
        dest: "../artifacts/rhcos-{{ rhcos_version }}-x86_64-gcp.x86_64.tar.gz"
        mode: '0644'
        timeout: 300
      when: rhcos_image_check.stdout == "not_found"
      register: rhcos_download
      tags: [rhcos]

    - name: Get current GCP project ID
      shell: gcloud config get-value project
      register: gcp_project_id
      changed_when: false
      when: rhcos_image_check.stdout == "not_found"
      tags: [rhcos]

    - name: Create temporary GCS bucket for RHCOS image
      shell: gsutil mb gs://{{ gcp_project_id.stdout }}-rhcos-temp || true
      when: rhcos_image_check.stdout == "not_found"
      tags: [rhcos]

    - name: Upload RHCOS image to GCS
      shell: gsutil cp ../artifacts/rhcos-{{ rhcos_version }}-x86_64-gcp.x86_64.tar.gz gs://{{ gcp_project_id.stdout }}-rhcos-temp/
      when: rhcos_image_check.stdout == "not_found"
      tags: [rhcos]

    - name: Create RHCOS image in GCP
      shell: |
        gcloud compute images create {{ rhcos_image_name }} \
          --source-uri=gs://{{ gcp_project_id.stdout }}-rhcos-temp/rhcos-{{ rhcos_version }}-x86_64-gcp.x86_64.tar.gz \
          --guest-os-features=UEFI_COMPATIBLE \
          --description="Red Hat Enterprise Linux CoreOS {{ rhcos_version }}"
      when: rhcos_image_check.stdout == "not_found"
      register: rhcos_image_create
      tags: [rhcos]

    - name: Cleanup temporary GCS bucket
      shell: |
        gsutil rm gs://{{ gcp_project_id.stdout }}-rhcos-temp/rhcos-{{ rhcos_version }}-x86_64-gcp.x86_64.tar.gz
        gsutil rb gs://{{ gcp_project_id.stdout }}-rhcos-temp
      when: rhcos_image_check.stdout == "not_found"
      ignore_errors: true
      tags: [rhcos]

    - name: Display RHCOS image management status
      debug:
        msg: "{{ 'âœ“ RHCOS image created successfully' if rhcos_image_check.stdout == 'not_found' else 'âœ“ RHCOS image already exists' }}"
      tags: [rhcos]

    # ================================
    # 4. Terraform Infrastructure Deployment
    # ================================
    
    - name: Initialize Terraform
      terraform:
        project_path: "../terraform"
        state: present
        force_init: true
      register: terraform_init
      tags: [terraform]

    - name: Plan Terraform deployment
      terraform:
        project_path: "../terraform"
        state: planned
        plan_file: terraform.tfplan
      register: terraform_plan
      tags: [terraform]

    - name: Apply Terraform configuration
      terraform:
        project_path: "../terraform"
        state: present
        plan_file: terraform.tfplan
      register: terraform_apply
      tags: [terraform]

    - name: Display infrastructure deployment status
      debug:
        msg: "âœ“ GCP infrastructure deployed successfully"
      tags: [terraform]

    - name: Wait for infrastructure to stabilize
      pause:
        seconds: 30
      tags: [terraform]

    # ================================
    # 5. Environment Setup
    # ================================
    
    - name: Get bastion external IP
      shell: gcloud compute instances describe {{ cluster_name }}-bastion --zone={{ bastion_zone }} --format="value(networkInterfaces[0].accessConfigs[0].natIP)"
      register: bastion_external_ip
      changed_when: false

    - name: Display deployment info
      debug:
        msg: |
          Starting basic OpenShift UPI automation for cluster: {{ cluster_name }}
          Bastion External IP: {{ bastion_external_ip.stdout }}
          Domain: {{ domain_name }}

    # ================================
    # 2. Copy kubeconfig to bastion
    # ================================
    
    - name: Ensure clusterconfig directory exists on bastion
      shell: |
        ssh -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ bastion_user }}@{{ bastion_external_ip.stdout }} '
        mkdir -p ~/clusterconfig/auth'
      changed_when: false

    - name: Copy kubeconfig to bastion
      shell: |
        scp -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ kubeconfig_path }} {{ bastion_user }}@{{ bastion_external_ip.stdout }}:~/clusterconfig/auth/kubeconfig

    - name: Download kubectl on bastion
      shell: |
        ssh -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ bastion_user }}@{{ bastion_external_ip.stdout }} '
        if ! command -v kubectl >/dev/null 2>&1; then
          echo "Downloading kubectl..."
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          echo "kubectl installed"
        else
          echo "kubectl already installed"
        fi'

    # ================================
    # 3. Get Infrastructure IPs
    # ================================
    
    - name: Get control plane IPs
      shell: |
        gcloud compute instances describe {{ cluster_name }}-control-1 --zone={{ control_plane_zones[0] }} --format="value(networkInterfaces[0].networkIP)"
        gcloud compute instances describe {{ cluster_name }}-control-2 --zone={{ control_plane_zones[1] }} --format="value(networkInterfaces[0].networkIP)"
        gcloud compute instances describe {{ cluster_name }}-control-3 --zone={{ control_plane_zones[2] }} --format="value(networkInterfaces[0].networkIP)"
      register: control_plane_ips_output
      changed_when: false

    - name: Set control plane IPs list
      set_fact:
        control_plane_ips: "{{ control_plane_ips_output.stdout_lines }}"

    - name: Display infrastructure IPs
      debug:
        msg: |
          Control Plane IPs: {{ control_plane_ips }}

    # ================================
    # 4. Wait for Bootstrap and Control Planes
    # ================================
    
    - name: Wait for bootstrap to complete and control planes to be ready
      shell: |
        ssh -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ bastion_user }}@{{ bastion_external_ip.stdout }} '
        export KUBECONFIG=~/clusterconfig/auth/kubeconfig
        echo "Waiting for bootstrap to complete and control planes to be ready..."
        
        # Wait for API to be accessible
        echo "Step 1: Waiting for API server to be accessible..."
        for i in {1..30}; do
          if kubectl get nodes >/dev/null 2>&1; then
            echo "âœ“ API server is accessible"
            break
          fi
          echo "  Waiting for API... ($i/30)"
          sleep 10
        done
        
        # Check if control planes are ready
        echo "Step 2: Waiting for control planes to be Ready..."
        for i in {1..20}; do
          READY_NODES=$(kubectl get nodes --no-headers | grep "control-plane" | grep " Ready " | wc -l 2>/dev/null || echo "0")
          echo "  Ready control plane nodes: $READY_NODES/3 ($i/20)"
          
          if [ "$READY_NODES" -ge "2" ]; then
            echo "âœ“ Bootstrap phase complete - control planes are ready"
            kubectl get nodes
            exit 0
          fi
          sleep 15
        done
        
        echo "âœ— Bootstrap did not complete in time"
        kubectl get nodes || echo "API not accessible"
        exit 1'
      register: bootstrap_status
      retries: 1
      until: bootstrap_status.rc == 0

    # ================================
    # 6. DNS Transition for api-int
    # ================================
    
    - name: Check current api-int DNS record
      shell: gcloud dns record-sets list --zone={{ dns_zone }} --filter="name=api-int.{{ domain_name }}." --format="value(rrdatas[0])"
      register: current_api_int_dns
      changed_when: false

    - name: Get bootstrap IP for comparison
      shell: gcloud compute instances describe {{ cluster_name }}-bootstrap --zone={{ bastion_zone }} --format="value(networkInterfaces[0].networkIP)"
      register: bootstrap_ip
      changed_when: false

    - name: Flip api-int DNS from bootstrap to control planes
      shell: |
        echo "Transitioning api-int from bootstrap ({{ bootstrap_ip.stdout }}) to control planes..."
        gcloud dns record-sets transaction start --zone={{ dns_zone }}
        gcloud dns record-sets transaction remove --zone={{ dns_zone }} --name=api-int.{{ domain_name }}. --type=A --ttl=300 {{ bootstrap_ip.stdout }}
        gcloud dns record-sets transaction add --zone={{ dns_zone }} --name=api-int.{{ domain_name }}. --type=A --ttl=300 {{ control_plane_ips | join(' ') }}
        gcloud dns record-sets transaction execute --zone={{ dns_zone }}
        echo "âœ“ DNS transition complete - api-int now points to control planes"
      when: bootstrap_status.rc == 0 and current_api_int_dns.stdout == bootstrap_ip.stdout

    - name: Display bootstrap completion status
      debug:
        msg: |
          âœ“ Bootstrap phase completed successfully!
          âœ“ Control planes are ready
          âœ“ api-int DNS transitioned to control planes
          
          Next: Waiting for workers to join...

    # ================================
    # 7. Worker CSR Approval
    # ================================
    
    - name: Wait for worker nodes to submit CSRs
      shell: |
        ssh -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ bastion_user }}@{{ bastion_external_ip.stdout }} '
        export KUBECONFIG=~/clusterconfig/auth/kubeconfig
        echo "Waiting for worker CSRs to appear..."
        
        for i in {1..20}; do
          PENDING_CSRS=$(kubectl get csr | grep "node-bootstrapper" | grep "Pending" | wc -l || echo "0")
          echo "  Pending worker CSRs: $PENDING_CSRS ($i/20)"
          
          if [ "$PENDING_CSRS" -ge "1" ]; then
            echo "âœ“ Worker CSRs found, ready for approval"
            exit 0
          fi
          sleep 15
        done
        
        echo "âš  No worker CSRs found yet, continuing anyway"
        exit 0'
      register: csr_wait_status

    - name: Approve worker node CSRs
      shell: |
        ssh -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ bastion_user }}@{{ bastion_external_ip.stdout }} '
        export KUBECONFIG=~/clusterconfig/auth/kubeconfig
        echo "Approving pending worker CSRs..."
        
        # Get all pending CSRs from node-bootstrapper (workers)
        PENDING_CSRS=$(kubectl get csr -o name | grep csr | while read csr; do
          if kubectl get $csr -o jsonpath="{.spec.request}" | base64 -d | grep -q "node-bootstrapper"; then
            if kubectl get $csr -o jsonpath="{.status.conditions[0].type}" | grep -q "Pending\|^$"; then
              echo $csr | cut -d/ -f2
            fi
          fi
        done)
        
        if [ -n "$PENDING_CSRS" ]; then
          echo "Approving CSRs: $PENDING_CSRS"
          for csr in $PENDING_CSRS; do
            kubectl certificate approve $csr
            echo "  âœ“ Approved: $csr"
          done
        else
          echo "No pending worker CSRs found"
        fi'
      register: csr_approval_result

    - name: Wait for workers to join cluster
      shell: |
        ssh -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ bastion_user }}@{{ bastion_external_ip.stdout }} '
        export KUBECONFIG=~/clusterconfig/auth/kubeconfig
        echo "Waiting for worker nodes to join cluster..."
        
        for i in {1..15}; do
          WORKER_NODES=$(kubectl get nodes --no-headers | grep -v "control-plane" | grep -v "master" | wc -l || echo "0")
          READY_WORKERS=$(kubectl get nodes --no-headers | grep -v "control-plane" | grep -v "master" | grep " Ready " | wc -l || echo "0")
          echo "  Worker nodes: $WORKER_NODES, Ready: $READY_WORKERS ($i/15)"
          
          if [ "$WORKER_NODES" -ge "1" ]; then
            echo "âœ“ Worker nodes have joined the cluster"
            kubectl get nodes
            exit 0
          fi
          sleep 20
        done
        
        echo "âš  Workers not yet joined, but continuing"
        kubectl get nodes || echo "No nodes found"
        exit 0'
      register: worker_join_status

    - name: Approve additional CSRs (serving certificates)
      shell: |
        ssh -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ bastion_user }}@{{ bastion_external_ip.stdout }} '
        export KUBECONFIG=~/clusterconfig/auth/kubeconfig
        echo "Checking for additional CSRs that may need approval..."
        
        # Wait a bit for serving CSRs to appear
        sleep 30
        
        # Approve any remaining pending CSRs
        PENDING_CSRS=$(kubectl get csr --no-headers | grep "Pending" | awk "{print \$1}")
        
        if [ -n "$PENDING_CSRS" ]; then
          echo "Approving additional CSRs: $PENDING_CSRS"
          for csr in $PENDING_CSRS; do
            kubectl certificate approve $csr
            echo "  âœ“ Approved: $csr"
          done
        else
          echo "No additional CSRs pending"
        fi'
      register: additional_csr_approval

    # ================================
    # 8. Final Cluster Status
    # ================================
    
    - name: Check final cluster status
      shell: |
        ssh -i {{ ssh_key_path }} -o StrictHostKeyChecking=no {{ bastion_user }}@{{ bastion_external_ip.stdout }} '
        export KUBECONFIG=~/clusterconfig/auth/kubeconfig
        echo "=== Final Cluster Status ==="
        kubectl get nodes
        echo ""
        echo "=== Cluster Operators Status ==="
        kubectl get clusteroperators | head -10'
      register: final_status
      ignore_errors: true

    - name: Display cluster status
      debug:
        var: final_status.stdout_lines

    - name: Display deployment summary
      debug:
        msg: |
          ðŸŽ‰ OpenShift UPI Complete Deployment Finished!
          
          âœ… Completed Steps:
          1. âœ“ Prerequisites validated
          2. âœ“ OpenShift ignition configs generated
          3. âœ“ RHCOS image available in GCP
          4. âœ“ GCP infrastructure deployed with Terraform
          5. âœ“ Bootstrap phase completed successfully
          6. âœ“ Control planes are Ready
          7. âœ“ api-int DNS transitioned from bootstrap to control planes  
          8. âœ“ Worker CSRs approved automatically
          9. âœ“ Workers joined cluster
          
          ðŸš€ Ready to Use:
          - Export kubeconfig: export KUBECONFIG=../clusterconfig/auth/kubeconfig
          - Check cluster: kubectl get nodes
          - Access console: https://console-openshift-console.apps.{{ domain_name }}
          - Admin password: cat ../clusterconfig/auth/kubeadmin-password
          
          ðŸ“‹ Management Commands:
          - SSH to bastion: ssh -i {{ ssh_key_path }} {{ bastion_user }}@{{ bastion_external_ip.stdout }}
          - Monitor operators: kubectl get clusteroperators
          - Destroy cluster: cd ../terraform && terraform destroy


